apiVersion: batch/v1
kind: Job # Deployment will automatically restart when killed. Use Pod if not needed
metadata:
  labels:
    k8s-app: student-curves
  generateName: jhma-g1-debug # replace <your_name> with something that identifies you
  namespace: rl-work
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: research
          image: rchal97/complex_loco_preview4
          imagePullPolicy: Always
          command: ["/bin/sh", "-c"] # replace this with your own job execution scripts
          args:
            - cd /workspace;
              cp /zqchen/git-clone-leggedstudio.sh git-clone-leggedstudio.sh;
              bash git-clone-leggedstudio.sh;
              export WANDB_API_KEY=`cd /zqchen && cat wandb_api_key`; 
              cd legged_studio/legged_learning_studio;
              git checkout main;
              cd /workspace/legged_studio/legged_learning_studio/legged_learning;
              /opt/conda/envs/rlgpu/bin/pip install -e .;
              cd /workspace/legged_studio/legged_learning_studio/legged_utils;
              /opt/conda/envs/rlgpu/bin/pip install -e .;
              cd /workspace/legged_studio/legged_learning_studio/complex_gym;
              /opt/conda/envs/rlgpu/bin/pip install -e .;
              /opt/conda/envs/rlgpu/bin/pip install natsort toolz;
              cd /workspace/legged_studio/legged_learning_studio;
              /opt/conda/envs/rlgpu/bin/python starter/train.py --num_envs 4096 --headless --cfg_env cfg/a1/motion_prior_more_simple/v2.yaml --cfg_train cfg/a1/train/motion_prior_asym_mh_more_simple/t-1/rec0.yaml --logdir /zqchen/legged_studio/a1_motion_prior_sto_t-1_asymmh_rr_rec0_v2/mlp_1 --add_label _a1_motion_prior_sto_t-1_asymmh_rr_rec0_v2_rand --seed 1 ;
          resources:
            requests:
              memory: "16Gi" # 16 Gb memory
              cpu: "4" # 4 CPUs
              nvidia.com/gpu: 1 # requesting X GPU
            limits:
              memory: "16Gi" # 276 Gb memory
              cpu: "4" # 8 CPUs
              nvidia.com/gpu: 1 # requesting X GPU
          volumeMounts:
            - mountPath: /zqchen
              name: zqchen
            - mountPath: /dev/shm
              name: dshm
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: NotIn
                    values:
                    - Tesla-K40c
                    - NVIDIA-GeForce-GTX-1070
                    - Tesla-T4
                    - NVIDIA-TITAN-Xp
                    - NVIDIA-GeForce-GTX-1080
                    - NVIDIA-GeForce-GTX-1080-Ti
                    - NVIDIA-GeForce-RTX-2080-Ti
                    - Quadro-M4000
                    - NVIDIA-A100-PCIE-40GB-MIG-2g.10gb
                    - NVIDIA-A100-80GB-PCIe-MIG-1g.10gb
                    - NVIDIA-A100-SXM4-80GB 
                  - key: kubernetes.io/hostname
                    operator: NotIn
                    values:
                      - nautilusg02.sci.cwru.edu
      volumes:
        - name: zqchen
          persistentVolumeClaim:
            claimName: zqchen 
        - name: dshm
          emptyDir:
            medium: Memory
